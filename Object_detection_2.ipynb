{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNy72wro3iaoG+Xivof+CfS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DoctorNoSense/narutohandsigndetector/blob/main/Object_detection_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow==2.14.0"
      ],
      "metadata": {
        "id": "EOle0svZAI-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IcSctgRa6zuE",
        "outputId": "421ce80f-7bb1-4ae8-b880-a49028670015"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k3v_kMEDpaOc"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "shutil.rmtree('/content/Tensorflow', ignore_errors=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "aX1FGLO7ApuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os"
      ],
      "metadata": {
        "id": "TJyRz2Sbv1g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CUSTOM_MODEL_NAME = 'my_ssd_mobnet'\n",
        "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
        "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
        "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
        "LABEL_MAP_NAME = 'label_map.pbtxt'"
      ],
      "metadata": {
        "id": "qpOq6uLTv14u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "paths = {\n",
        "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
        "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
        "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
        "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
        "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
        "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
        "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
        "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME),\n",
        "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'),\n",
        "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'),\n",
        "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
        "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
        " }"
      ],
      "metadata": {
        "id": "rmORJ1d4v3ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = {\n",
        "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
        "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME),\n",
        "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
        "}"
      ],
      "metadata": {
        "id": "5eHJOPrJv4VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for path in paths.values():\n",
        "    if not os.path.exists(path):\n",
        "        if os.name == 'posix':\n",
        "            !mkdir -p {path}\n",
        "        if os.name == 'nt':\n",
        "            !mkdir {path}"
      ],
      "metadata": {
        "id": "P6hkqvzCv5tA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name=='nt':\n",
        "    !pip install wget\n",
        "    import wget"
      ],
      "metadata": {
        "id": "CiXOVnb8v63L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
        "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI93RHC7w66o",
        "outputId": "75edf0b0-5488-4a5f-b1e4-1b86e993fafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/models'...\n",
            "remote: Enumerating objects: 90280, done.\u001b[K\n",
            "remote: Counting objects: 100% (75/75), done.\u001b[K\n",
            "remote: Compressing objects: 100% (58/58), done.\u001b[K\n",
            "remote: Total 90280 (delta 33), reused 37 (delta 17), pack-reused 90205\u001b[K\n",
            "Receiving objects: 100% (90280/90280), 604.94 MiB | 25.48 MiB/s, done.\n",
            "Resolving deltas: 100% (65055/65055), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install Tensorflow Object Detection\n",
        "if os.name=='posix':\n",
        "    !apt-get install protobuf-compiler\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install .\n",
        "\n",
        "if os.name=='nt':\n",
        "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
        "    wget.download(url)\n",
        "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
        "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
        "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))\n",
        "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
        "    !cd Tensorflow/models/research/slim && pip install -e ."
      ],
      "metadata": {
        "id": "lj-uH6-Ew8kq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
        "# Verify Installation\n",
        "!python {VERIFICATION_SCRIPT}"
      ],
      "metadata": {
        "id": "78imO7JjxSCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip uninstall protobuf matplotlib -y\n",
        "# !pip install protobuf matplotlib==3.2"
      ],
      "metadata": {
        "id": "075GR2x_xR-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import object_detection"
      ],
      "metadata": {
        "id": "kvpBcnnzxR7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name =='posix':\n",
        "    !wget {PRETRAINED_MODEL_URL}\n",
        "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
        "if os.name == 'nt':\n",
        "    wget.download(PRETRAINED_MODEL_URL)\n",
        "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
        "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6mqhfcUyaP3",
        "outputId": "f51c723a-7bb0-4374-8f4e-e82346be5a42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-01-05 14:12:55--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz\n",
            "Resolving download.tensorflow.org (download.tensorflow.org)... 173.194.79.207, 108.177.96.207, 108.177.119.207, ...\n",
            "Connecting to download.tensorflow.org (download.tensorflow.org)|173.194.79.207|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 20515344 (20M) [application/x-tar]\n",
            "Saving to: ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’\n",
            "\n",
            "ssd_mobilenet_v2_fp 100%[===================>]  19.56M  18.0MB/s    in 1.1s    \n",
            "\n",
            "2024-01-05 14:12:57 (18.0 MB/s) - ‘ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz’ saved [20515344/20515344]\n",
            "\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/checkpoint\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/checkpoint/ckpt-0.index\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/pipeline.config\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/saved_model.pb\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
            "ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8/saved_model/variables/variables.index\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = [{'name':'tiger', 'id':1}, {'name':'zero', 'id':2}]\n",
        "\n",
        "with open(files['LABELMAP'], 'w') as f:\n",
        "    for label in labels:\n",
        "        f.write('item { \\n')\n",
        "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
        "        f.write('\\tid:{}\\n'.format(label['id']))\n",
        "        f.write('}\\n')"
      ],
      "metadata": {
        "id": "7xxSAcmjyaNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OPTIONAL IF RUNNING ON COLAB\n",
        "ARCHIVE_FILES = os.path.join(paths['IMAGE_PATH'], 'archive.tar.gz')\n",
        "if os.path.exists(ARCHIVE_FILES):\n",
        "  !tar -zxvf {ARCHIVE_FILES}"
      ],
      "metadata": {
        "id": "uAQ4FgxkyaLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
        "    !git clone https://github.com/nicknochnack/GenerateTFRecord {paths['SCRIPTS_PATH']}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hU8Hqk9_yrET",
        "outputId": "6917373d-cc45-4a06-95ec-e40b674ba377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Tensorflow/scripts'...\n",
            "remote: Enumerating objects: 3, done.\u001b[K\n",
            "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 0), reused 1 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (3/3), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')}\n",
        "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-nZMycAysPw",
        "outputId": "a1cf1055-e998-4215-90a1-f55061086c5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-05 14:13:15.512760: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-05 14:13:15.512814: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-05 14:13:15.514365: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n",
            "2024-01-05 14:13:19.820038: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-05 14:13:19.820094: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-05 14:13:19.821535: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.name =='posix':\n",
        "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
        "if os.name == 'nt':\n",
        "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}"
      ],
      "metadata": {
        "id": "CmMcP0u01fwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from object_detection.utils import config_util\n",
        "from object_detection.protos import pipeline_pb2\n",
        "from google.protobuf import text_format"
      ],
      "metadata": {
        "id": "tfXIVcSd1qbP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "tejOmumY-6CQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR2Wmd_y-2M7",
        "outputId": "48b5fb98-d419-41ba-e71d-f220d7a84505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip list"
      ],
      "metadata": {
        "id": "Pxl8_CkS-MrM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])"
      ],
      "metadata": {
        "id": "j0TCubMI1qpi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oZQTahqv1smt",
        "outputId": "70050c13-10ea-4775-c3dd-002055338d7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available objects for config:\n",
            "     AliasManager\n",
            "     ColabHistoryManager\n",
            "     ColabKernelApp\n",
            "     DisplayFormatter\n",
            "     IPCompleter\n",
            "     InlineBackend\n",
            "     LoggingMagics\n",
            "     MagicsManager\n",
            "     OSMagics\n",
            "     PrefilterManager\n",
            "     ScriptMagics\n",
            "     Shell\n",
            "     StoreMagics\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:\n",
        "    proto_str = f.read()\n",
        "    text_format.Merge(proto_str, pipeline_config)"
      ],
      "metadata": {
        "id": "7xcHNdmP1tgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline_config.model.ssd.num_classes = len(labels)\n",
        "pipeline_config.train_config.batch_size = 4\n",
        "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
        "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
        "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
        "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
        "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
        "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
      ],
      "metadata": {
        "id": "4h5y8hF31vo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config_text = text_format.MessageToString(pipeline_config)\n",
        "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:\n",
        "    f.write(config_text)"
      ],
      "metadata": {
        "id": "NDO72H4y1wh_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
      ],
      "metadata": {
        "id": "lgyXcPqu16iR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=2000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])"
      ],
      "metadata": {
        "id": "LknXI9bq16fU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(command)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQD7C0Fm16GP",
        "outputId": "58c3ffdb-84cb-4317-cad7-aac496edf11a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/my_ssd_mobnet --pipeline_config_path=Tensorflow/workspace/models/my_ssd_mobnet/pipeline.config --num_train_steps=2000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tf.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6hvomu07yue",
        "outputId": "c179e822-c460-4129-c28e-997d441af120"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!{command}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osDlkl9a19u9",
        "outputId": "05b70b59-d223-4fee-aa26-4b539dda4383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-01-05 14:02:31.361379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-05 14:02:31.361434: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-05 14:02:31.363381: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-05 14:02:32.629490: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2024-01-05 14:02:36.049880: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "I0105 14:02:36.051310 139758029300352 mirrored_strategy.py:423] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
            "INFO:tensorflow:Maybe overwriting train_steps: 2000\n",
            "I0105 14:02:36.078205 139758029300352 config_util.py:552] Maybe overwriting train_steps: 2000\n",
            "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
            "I0105 14:02:36.078428 139758029300352 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "W0105 14:02:36.113857 139758029300352 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py:563: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "rename to distribute_datasets_from_function\n",
            "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0105 14:02:36.121838 139758029300352 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "I0105 14:02:36.122105 139758029300352 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
            "INFO:tensorflow:Number of filenames to read: 1\n",
            "I0105 14:02:36.122287 139758029300352 dataset_builder.py:80] Number of filenames to read: 1\n",
            "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
            "W0105 14:02:36.122380 139758029300352 dataset_builder.py:86] num_readers has been reduced to 1 to match input file shards.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "W0105 14:02:36.131524 139758029300352 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:100: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "W0105 14:02:36.153365 139758029300352 deprecation.py:50] From /usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py:235: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.map()\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
            "    tf.compat.v1.app.run()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
            "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 308, in run\n",
            "    _run_main(main, args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/absl/app.py\", line 254, in _run_main\n",
            "    sys.exit(main(argv))\n",
            "  File \"/content/Tensorflow/models/research/object_detection/model_main_tf2.py\", line 105, in main\n",
            "    model_lib_v2.train_loop(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py\", line 563, in train_loop\n",
            "    train_input = strategy.experimental_distribute_datasets_from_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py\", line 383, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1563, in experimental_distribute_datasets_from_function\n",
            "    return self.distribute_datasets_from_function(dataset_fn, options)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/distribute_lib.py\", line 1554, in distribute_datasets_from_function\n",
            "    return self._extended._distribute_datasets_from_function(  # pylint: disable=protected-access\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/mirrored_strategy.py\", line 613, in _distribute_datasets_from_function\n",
            "    return input_util.get_distributed_datasets_from_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/input_util.py\", line 144, in get_distributed_datasets_from_function\n",
            "    return input_lib.DistributedDatasetsFromFunction(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1143, in __init__\n",
            "    self.build()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1165, in build\n",
            "    _create_datasets_from_function_with_input_context(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/distribute/input_lib.py\", line 1680, in _create_datasets_from_function_with_input_context\n",
            "    dataset = dataset_fn(ctx)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/model_lib_v2.py\", line 554, in train_dataset_fn\n",
            "    train_input = inputs.train_input(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/inputs.py\", line 908, in train_input\n",
            "    dataset = INPUT_BUILDER_UTIL_MAP['dataset_build'](\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py\", line 250, in build\n",
            "    dataset = dataset_map_fn(dataset, decoder.decode, batch_size,\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/object_detection/builders/dataset_builder.py\", line 235, in dataset_map_fn\n",
            "    dataset = dataset.map_with_legacy_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/deprecation.py\", line 383, in new_func\n",
            "    return func(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4128, in map_with_legacy_function\n",
            "    return map_op._map_v1_with_legacy_function(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\", line 85, in _map_v1_with_legacy_function\n",
            "    _ParallelMapDataset(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/map_op.py\", line 148, in __init__\n",
            "    self._map_func = structured_function.StructuredFunctionWrapper(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\", line 272, in __init__\n",
            "    self._function.add_to_graph(ops.get_default_graph())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/function.py\", line 579, in add_to_graph\n",
            "    self._create_definition_if_needed()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/function.py\", line 412, in _create_definition_if_needed\n",
            "    self._create_definition_if_needed_impl()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/function.py\", line 430, in _create_definition_if_needed_impl\n",
            "    temp_graph = func_graph_from_py_func(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/function.py\", line 1007, in func_graph_from_py_func\n",
            "    outputs = func(*func_graph.inputs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\", line 178, in wrapped_fn\n",
            "    ret = wrapper_helper(*args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/data/ops/structured_function.py\", line 161, in wrapper_helper\n",
            "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 693, in wrapper\n",
            "    raise e.ag_error_metadata.to_exception(e)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 690, in wrapper\n",
            "    return converted_call(f, args, kwargs, options=options)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 439, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/__autograph_generated_fileh16b9jp_.py\", line 74, in tf__decode\n",
            "    tensors = ag__.converted_call(ag__.ld(decoder).decode, (ag__.ld(serialized_example),), dict(items=ag__.ld(keys)), fscope)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 439, in converted_call\n",
            "    result = converted_f(*effective_args, **kwargs)\n",
            "  File \"/tmp/__autograph_generated_filel8f_ve9p.py\", line 81, in tf__decode\n",
            "    ag__.for_stmt(ag__.ld(items), None, loop_body_1, get_state_3, set_state_3, (), {'iterate_names': 'item'})\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 449, in for_stmt\n",
            "    for_fn(iter_, extra_test, body, get_state, set_state, symbol_names, opts)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 500, in _py_for_stmt\n",
            "    body(target)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 466, in protected_body\n",
            "    original_body(protected_iter)\n",
            "  File \"/tmp/__autograph_generated_filel8f_ve9p.py\", line 77, in loop_body_1\n",
            "    ag__.converted_call(ag__.ld(outputs).append, (ag__.converted_call(ag__.ld(handler).tensors_to_item, (ag__.ld(keys_to_tensors),), None, fscope),), None, fscope)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 441, in converted_call\n",
            "    result = converted_f(*effective_args)\n",
            "  File \"/tmp/__autograph_generated_file1q96cdvv.py\", line 39, in tf__tensors_to_item\n",
            "    ag__.if_stmt(ag__.ld(self)._repeated, if_body, else_body, get_state, set_state, ('do_return', 'retval_'), 2)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1217, in if_stmt\n",
            "    _py_if_stmt(cond, body, orelse)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/operators/control_flow.py\", line 1270, in _py_if_stmt\n",
            "    return body() if cond else orelse()\n",
            "  File \"/tmp/__autograph_generated_file1q96cdvv.py\", line 35, in else_body\n",
            "    retval_ = ag__.converted_call(ag__.ld(self)._decode, (ag__.ld(image_buffer), ag__.ld(image_format)), None, fscope)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/tensorflow/python/autograph/impl/api.py\", line 441, in converted_call\n",
            "    result = converted_f(*effective_args)\n",
            "  File \"/tmp/__autograph_generated_fileppr0jbm8.py\", line 80, in tf___decode\n",
            "    image = ag__.converted_call(ag__.ld(control_flow_ops).case, (ag__.ld(pred_fn_pairs),), dict(default=ag__.ld(check_jpeg), exclusive=True), fscope)\n",
            "AttributeError: in user code:\n",
            "\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/object_detection/data_decoders/tf_example_decoder.py\", line 556, in decode  *\n",
            "        tensors = decoder.decode(serialized_example, items=keys)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py\", line 722, in decode  *\n",
            "        outputs.append(handler.tensors_to_item(keys_to_tensors))\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py\", line 405, in tensors_to_item  *\n",
            "        return self._decode(image_buffer, image_format)\n",
            "    File \"/usr/local/lib/python3.10/dist-packages/tf_slim/data/tfexample_decoder.py\", line 453, in _decode  *\n",
            "        image = control_flow_ops.case(\n",
            "\n",
            "    AttributeError: module 'tensorflow.python.ops.control_flow_ops' has no attribute 'case'\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tpo5JxFo1_ac"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}